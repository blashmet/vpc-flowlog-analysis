---
AWSTemplateFormatVersion: "2010-09-09"
Description: Kinesis infrastructure for vpc flowlog visualization.

Parameters:
  VPCId:
    Type: String
    Description: The VPC ID for the source VPC where all network flows will be logged and collected for analysis. Also used for S3 bucket name.

  S3CleanupLambdaArn:
    Type: String
    Description: Lambda to cleanup buckets before deletion.

Resources:
#ROLES
  FirehoseTransformationLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${AWS::StackName}-FHTransformRole"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-FirehosePolicy"
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
  FirehoseDeliveryRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${AWS::StackName}-FirehoseRole"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - firehose.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-FirehosePolicy"
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - glue:GetTableVersions
                Resource: "*"
              - Effect: Allow
                Action:
                  - s3:*
                Resource:
                  - !Join ["", ["arn:aws:s3:::", !Ref S3Bucket]]
                  - !Join ["", ["arn:aws:s3:::", !Ref S3Bucket, "/*"]]
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                  - lambda:GetFunctionConfiguration
                Resource:
                  - !GetAtt FirehoseTransformationFunction.Arn
  KDARole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${AWS::StackName}-KDARole"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - kinesisanalytics.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-KDAPolicy"
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - firehose:DescribeDeliveryStream
                  - firehose:Get*
                Resource: !GetAtt KDFIngestion.Arn
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                  - lambda:GetFunctionConfiguration
                Resource:
                  - !GetAtt KDAOutputLambda.Arn
                  - !GetAtt KDAPreprocessLambda.Arn
                  - !Join
                    - ":"
                    - - !GetAtt KDAPreprocessLambda.Arn
                      - "$LATEST"
                  - !Join
                    - ":"
                    - - !GetAtt KDAOutputLambda.Arn
                      - "$LATEST"
  CWMetricsUpdateLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${AWS::StackName}-KDAOutputLambdaRole"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-KDAPolicy"
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "arn:aws:logs:*:*:*"
              - Effect: Allow
                Action:
                  - cloudwatch:PutMetricData
                Resource:
                  - "*"
  UpdateFirehoseFormatConversionLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${AWS::StackName}-FirehoseConversionRole"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-FirehosePolicy"
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - firehose:UpdateDestination
                  - firehose:DescribeDeliveryStream
                  - iam:PassRole
                Resource: "*"
  CWLogsSubscriptionRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${AWS::StackName}-CWLogsSubToFirehose"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - !Sub "logs.${AWS::Region}.amazonaws.com"
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-CWLogsSubToFHPolicy"
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - firehose:DescribeDeliveryStream
                  - firehose:Put*
                Resource: !GetAtt KDFIngestion.Arn
  FlowLogsRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${AWS::StackName}-FlowLogsRole"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - vpc-flow-logs.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-FlowLogsPolicy"
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:DescribeLogGroups
                  - logs:DescribeLogStreams
                  - logs:PutLogEvents
                Resource: "*"
#CLOUDWATCH
  CWLogsSubscriptionFilter:
    Type: "AWS::Logs::SubscriptionFilter"
    Properties:
      DestinationArn: !GetAtt KDFIngestion.Arn
      LogGroupName: !Ref FlowLogLogGroup
      RoleArn: !GetAtt CWLogsSubscriptionRole.Arn
      FilterPattern: "[version,accountid,interfaceid,srcaddr,dstaddr,srcport,dstport,protocol,packets,bytes,start,end,action,logstatus]"

  FirehoseTransformationFunctionLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties:
      LogGroupName: !Sub "/aws/lambda/${AWS::StackName}-FHTransformFunction"

  FirehoseUpdateFormatConversionFunctionLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties:
      LogGroupName: !Sub "/aws/lambda/${AWS::StackName}-FirehoseConversion"

  KDAOutputLambdaLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties:
      LogGroupName: !Sub "/aws/lambda/${AWS::StackName}-KDADestinationFunction"

  FlowLogLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties:
      LogGroupName: !Sub "${AWS::StackName}-log-group"
  KDAPreprocessLambdaLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties:
      LogGroupName: !Sub "/aws/lambda/${AWS::StackName}-KDAPreprocessFunction"
  UpdateFirehoseDataFormatConversionLambdaLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties:
      LogGroupName: !Sub "/aws/lambda/${AWS::StackName}-KDFUpdateDataFormat"
  KDFIngestionLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties:
      LogGroupName: !Sub "/aws/lambda/${AWS::StackName}-KDFIngestion"  
  
  CWDashboard:
    Type: "AWS::CloudWatch::Dashboard"
    Properties:
      DashboardName: !Sub "${AWS::StackName}"
      DashboardBody: !Sub |
        {
            "widgets": [
                {
                    "type": "metric",
                    "x": 0,
                    "y": 0,
                    "width": 24,
                    "height": 9,
                    "styles": "undefined",
                    "properties": {
                        "view": "timeSeries",
                        "stacked": false,
                        "metrics": [
                            [ "VPC-Flow-Log-Analysis", "TotalRejectedPackets" ]
                        ],
                        "region": "${AWS::Region}",
                        "stat": "Sum",
                        "period": 900,
                        "title": "Total Rejected Packets"
                    }
                }
            ]
        }
#LAMBDAS
  FirehoseTransformationFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub "${AWS::StackName}-FHTransformFunction"
      Description: "Decompresses and extracts VPC flow log records from CW log data"
      Handler: "index.handler"
      Role: !GetAtt FirehoseTransformationLambdaRole.Arn
      Runtime: "nodejs12.x"
      Timeout: 180
      Code:
        S3Bucket: !Sub "utility-lambdas-${AWS::Region}"
        S3Key: "firehose-process-vpc-flow-logs.zip"
    DependsOn: FirehoseTransformationFunctionLogGroup
  FirehoseUpdateFormatConversionFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub "${AWS::StackName}-FirehoseConversion"
      Description: "Updates the Firehose delivery stream to enable it for record format conversion"
      Handler: "index.handler"
      Role: !GetAtt UpdateFirehoseFormatConversionLambdaRole.Arn
      Runtime: "nodejs12.x"
      Timeout: 180
      Code:
        S3Bucket: !Sub "utility-lambdas-${AWS::Region}"
        S3Key: "firehose-update-format-conversion.zip"
    DependsOn: FirehoseUpdateFormatConversionFunctionLogGroup
  KDAOutputLambda:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub "${AWS::StackName}-KDADestinationFunction"
      Description: "Takes the output from KDA and writes to CW logs"
      Handler: "index.handler"
      Role: !GetAtt CWMetricsUpdateLambdaRole.Arn
      Runtime: "nodejs12.x"
      Timeout: 180
      Code:
        S3Bucket: !Sub "utility-lambdas-${AWS::Region}"
        S3Key: "kda-update-cw-metrics.zip"
    DependsOn: KDAOutputLambdaLogGroup

  KDAPreprocessLambda:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub "${AWS::StackName}-KDAPreprocessFunction"
      Description: "Takes the compressed records from input and decompresses them so they can be used by KDA"
      Handler: "index.handler"
      Role: !GetAtt CWMetricsUpdateLambdaRole.Arn
      Runtime: "nodejs12.x"
      Timeout: 180
      Code:
        S3Bucket: !Sub "utility-lambdas-${AWS::Region}"
        S3Key: "kda-preprocess-flowlogs.zip"
    DependsOn: KDAPreprocessLambdaLogGroup

  UpdateFirehoseDataFormatConversionLambda:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub "${AWS::StackName}-KDFUpdateDataFormat"
      Description: "Updates the Firehose delivery stream so that it converts data to Parquet.  This feature was unable to be set by CloudFormation at the time."
      Handler: "index.handler"
      Role: !GetAtt CWMetricsUpdateLambdaRole.Arn
      Runtime: "nodejs12.x"
      Timeout: 180
      Code:
        S3Bucket: !Sub "utility-lambdas-${AWS::Region}"
        S3Key: "kda-preprocess-flowlogs.zip"
    DependsOn: UpdateFirehoseDataFormatConversionLambdaLogGroup
#GLUE
  GlueDatabase:
    Type: "AWS::Glue::Database"
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Select [1, !Split ["-", !Ref VPCId]]
        Description: "Database containing tables of VPC flow log records."
  GlueTable:
    Type: "AWS::Glue::Table"
    Properties:
      TableInput:
        Name: !Select [1, !Split ["-", !Ref VPCId]]
        Parameters:
            classification: parquet
            projection.enabled: 'true'
            projection.datehour.type: date
            projection.datehour.range: '2020/01/01/00,NOW'
            projection.datehour.format: yyyy/MM/dd/HH
            projection.datehour.interval: '1'
            projection.datehour.interval.unit: HOURS
            storage.location.template: !Sub "s3://${S3Bucket}/parquet/${!datehour}"
        PartitionKeys:
            - Name: datehour
              Type: string
 
        StorageDescriptor:
          Location: !Join
            - "/"
            - - "s3:/"
              - !Ref S3Bucket
              - "parquet/"
          Columns:
            - Name: start
              Type: timestamp
            - Name: end
              Type: timestamp
            - Name: action
              Type: string
            - Name: logstatus
              Type: string
            - Name: version
              Type: string
            - Name: accountid
              Type: string
            - Name: interfaceid
              Type: string
            - Name: srcaddr
              Type: string
            - Name: dstaddr
              Type: string
            - Name: srcport
              Type: string
            - Name: dstport
              Type: string
            - Name: protocol
              Type: string
            - Name: packets
              Type: double
            - Name: bytes
              Type: double

          InputFormat: "org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat"
          OutputFormat: "org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat"
          SerdeInfo:
            SerializationLibrary: "org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe"
            Parameters: { "serialization.format": 1 }
        TableType: EXTERNAL_TABLE
      DatabaseName: !Ref GlueDatabase
      CatalogId: !Ref AWS::AccountId
#KINESIS
  KDFIngestion:
    Type: "AWS::KinesisFirehose::DeliveryStream"
    Properties:
      DeliveryStreamName: !Sub "${AWS::StackName}-ingestion-delivery-stream"
      DeliveryStreamType: DirectPut
      ExtendedS3DestinationConfiguration:
        BucketARN: !GetAtt S3Bucket.Arn
        BufferingHints:
          IntervalInSeconds: 300
          SizeInMBs: 128
        CloudWatchLoggingOptions:
          Enabled: False

        RoleARN: !GetAtt FirehoseDeliveryRole.Arn
        Prefix: "parquet/"
        ErrorOutputPrefix: "/"
        CompressionFormat: UNCOMPRESSED
        ProcessingConfiguration:
          Enabled: True
          Processors:
            - Type: Lambda
              Parameters:
                - ParameterName: LambdaArn
                  ParameterValue: !GetAtt FirehoseTransformationFunction.Arn
                - ParameterName: RoleArn
                  ParameterValue: !GetAtt FirehoseDeliveryRole.Arn

  KDAApplication:
    Type: "AWS::KinesisAnalytics::Application"
    Properties:
      ApplicationName: !Sub "${AWS::StackName}"
      ApplicationCode: >
        CREATE OR REPLACE STREAM "DESTINATION_SQL_STREAM" (
            "window_timestamp" BIGINT,
            "metric_name" VARCHAR(32),
            "metric_value" DOUBLE,
            "dimension_1_name" VARCHAR(255),
            "dimension_1_value" VARCHAR(255),
            "dimension_2_name" VARCHAR(255),
            "dimension_2_value" VARCHAR(255),
            "dimension_3_name" VARCHAR(255),
            "dimension_3_value" VARCHAR(255),
            "dimension_4_name" VARCHAR(255),
            "dimension_4_value" VARCHAR(255),
            "dimension_5_name" VARCHAR(255),
            "dimension_5_value" VARCHAR(255));


        /*
        CREATE OR REPLACE STREAM "ALL_REJECTED_STREAM" (
            "start_timestamp" BIGINT,
            "end_timestamp" BIGINT,
            "action" VARCHAR(8),
            "log_status" VARCHAR(10),
            "version" INTEGER,
            "account_id" VARCHAR(16),
            "interface" VARCHAR(16),
            "source_addr" VARCHAR(16),
            "destination_addr" VARCHAR(16),
            "source_port" INTEGER,
            "destination_port" INTEGER,
            "protocol" INTEGER,
            "packets" INTEGER,
            "bytes" INTEGER);
        */

        CREATE OR REPLACE STREAM "REJECTED_BY_PORT_STREAM" (
            "window_timestamp" BIGINT,
            "rejected_packet_count" DOUBLE,
            "destination_port" INTEGER);

        CREATE OR REPLACE STREAM "REJECTED_BY_PROTOCOL_STREAM" (
            "window_timestamp" BIGINT,
            "rejected_packet_count" DOUBLE,
            "protocol" INTEGER);

        CREATE OR REPLACE STREAM "REJECTED_COUNT_STREAM" (
            "window_timestamp" BIGINT,
            "rejected_packet_count" DOUBLE);




        CREATE OR REPLACE  PUMP "REJECTED_BY_PORT_PUMP" AS INSERT INTO "REJECTED_BY_PORT_STREAM"
            SELECT STREAM
                    UNIX_TIMESTAMP(STEP(to_timestamp("start_timestamp" * 1000) BY INTERVAL '10' SECOND)) as "window_timestamp",
                    SUM("packets") as "rejected_packet_count",
                   "destination_port" as "destination_port"
                FROM
                    "SOURCE_SQL_STREAM_001"
                GROUP BY
                    STEP("SOURCE_SQL_STREAM_001".ROWTIME BY INTERVAL '1' MINUTE),
                    UNIX_TIMESTAMP(STEP(to_timestamp("start_timestamp" * 1000) BY INTERVAL '10' SECOND)),
                    "destination_port";


        CREATE OR REPLACE  PUMP "REJECTED_BY_PROTOCOL_PUMP" AS INSERT INTO "REJECTED_BY_PROTOCOL_STREAM"
            SELECT STREAM
                    UNIX_TIMESTAMP(STEP(to_timestamp("start_timestamp" * 1000) BY INTERVAL '10' SECOND)) as "window_timestamp",
                    SUM("packets") as "rejected_packet_count",
                   "protocol" as "protocol"
                FROM
                    "SOURCE_SQL_STREAM_001"
                WHERE
                    "action" = 'REJECT'
                GROUP BY
                    STEP("SOURCE_SQL_STREAM_001".ROWTIME BY INTERVAL '1' MINUTE),
                    UNIX_TIMESTAMP(STEP(to_timestamp("start_timestamp" * 1000) BY INTERVAL '10' SECOND)),
                    "protocol";

        CREATE OR REPLACE  PUMP "REJECTED_COUNT_PUMP" AS INSERT INTO "REJECTED_COUNT_STREAM"
            SELECT STREAM
                    UNIX_TIMESTAMP(STEP(to_timestamp("start_timestamp" * 1000) BY INTERVAL '10' SECOND)) as "window_timestamp",
                    SUM("packets") as "rejected_packet_count"
                FROM
                    "SOURCE_SQL_STREAM_001"
                WHERE
                    "action" = 'REJECT'
                GROUP BY
                    STEP("SOURCE_SQL_STREAM_001".ROWTIME BY INTERVAL '1' MINUTE),
                    UNIX_TIMESTAMP(STEP(to_timestamp("start_timestamp" * 1000) BY INTERVAL '10' SECOND));



        CREATE OR REPLACE  PUMP "STREAM_PUMP" AS INSERT INTO "DESTINATION_SQL_STREAM"
            SELECT STREAM
                "window_timestamp",
                'RejectedPackets',
                "rejected_packet_count",
                'destination_port',
                CAST("destination_port" AS VARCHAR(255)),
                '',
                '',
                '',
                '',
                '',
                '',
                '',
                ''
            FROM
                "REJECTED_BY_PORT_STREAM"
            UNION ALL
            SELECT STREAM
                "window_timestamp",
                'RejectedPackets',
                "rejected_packet_count",
                'protocol',
                CAST("protocol" AS VARCHAR(255)),
                '',
                '',
                '',
                '',
                '',
                '',
                '',
                ''
            FROM
                "REJECTED_BY_PROTOCOL_STREAM"
            UNION ALL
            SELECT STREAM
                "window_timestamp",
                'TotalRejectedPackets',
                "rejected_packet_count",
                '',
                '',
                '',
                '',
                '',
                '',
                '',
                '',
                '',
                ''
            FROM
                "REJECTED_COUNT_STREAM";

      Inputs:
        - NamePrefix: "SOURCE_SQL_STREAM"
          InputProcessingConfiguration:
            InputLambdaProcessor:
              ResourceARN: !GetAtt KDAPreprocessLambda.Arn
              RoleARN: !GetAtt KDARole.Arn
          InputSchema:
            RecordFormat:
              RecordFormatType: JSON
            RecordColumns:
              - Mapping: "$.logEvents[0:].extractedFields.start"
                Name: start_timestamp
                SqlType: BIGINT
              - Mapping: "$.logEvents[0:].extractedFields.end"
                Name: end_timestamp
                SqlType: BIGINT
              - Mapping: "$.logEvents[0:].extractedFields.action"
                Name: action
                SqlType: VARCHAR(8)
              - Mapping: "$.logEvents[0:].extractedFields.logstatus"
                Name: log_status
                SqlType: VARCHAR(10)
              - Mapping: "$.logEvents[0:].extractedFields.version"
                Name: version
                SqlType: INTEGER
              - Mapping: "$.logEvents[0:].extractedFields.accountid"
                Name: account_id
                SqlType: VARCHAR(16)
              - Mapping: "$.logEvents[0:].extractedFields.interfaceid"
                Name: interface_id
                SqlType: VARCHAR(16)
              - Mapping: "$.logEvents[0:].extractedFields.srcaddr"
                Name: source_addr
                SqlType: VARCHAR(16)
              - Mapping: "$.logEvents[0:].extractedFields.dstaddr"
                Name: destination_addr
                SqlType: VARCHAR(16)
              - Mapping: "$.logEvents[0:].extractedFields.srcport"
                Name: source_port
                SqlType: INTEGER
              - Mapping: "$.logEvents[0:].extractedFields.dstport"
                Name: destination_port
                SqlType: INTEGER
              - Mapping: "$.logEvents[0:].extractedFields.protocol"
                Name: protocol
                SqlType: INTEGER
              - Mapping: "$.logEvents[0:].extractedFields.packets"
                Name: packets
                SqlType: INTEGER
              - Mapping: "$.logEvents[0:].extractedFields.bytes"
                Name: bytes
                SqlType: INTEGER
          KinesisFirehoseInput:
            ResourceARN: !GetAtt KDFIngestion.Arn
            RoleARN: !GetAtt KDARole.Arn
#VPC FLOW LOGS
  VPCFlowLog:
    Type: "AWS::EC2::FlowLog"
    Properties:
      DeliverLogsPermissionArn: !GetAtt FlowLogsRole.Arn
      LogGroupName: !Ref FlowLogLogGroup
      ResourceId: !Ref VPCId
      ResourceType: VPC
      TrafficType: ALL
    DependsOn: FlowLogLogGroup
  S3Bucket:
    Type: "AWS::S3::Bucket"
    Properties:
      BucketName: !Sub "${AWS::StackName}"
  CleanupBucketOnDelete:
    Type: Custom::CustomCleanupBucketResource
    Properties:
      ServiceToken: !Ref S3CleanupLambdaArn
      BucketName: !Ref S3Bucket
      DependsOn: !Ref S3Bucket
  Custom:
    Type: Custom::ConfigureFirehoseResource
    Properties:
      ServiceToken: !GetAtt FirehoseUpdateFormatConversionFunction.Arn
      DeliveryStreamName: !Ref KDFIngestion
      GlueDatabaseName: !Ref GlueDatabase
      GlueTableName: !Ref GlueTable
      FirehoseRole: !GetAtt FirehoseDeliveryRole.Arn
      Region: !Ref AWS::Region
